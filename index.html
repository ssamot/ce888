<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>CE888 2017</title>

    <!-- Bootstrap -->
    <link href="./bootstrap/css/bootstrap.cr.css" rel="stylesheet">
    <link href="./ce888.css" rel="stylesheet">
    <link rel="shortcut icon" href="graphics/favicon.ico">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>
<nav class="navbar navbar-default navbar-fixed-top">

     
      <div class="container">
       <a href="#data-science-and-decision-making" class="navbar-brand">CE888</a>
        <div class="navbar-header">
          <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
           
        </div>
        <div id="navbar" class="collapse navbar-collapse">
          <ul class="nav navbar-nav">


            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="Lectures">Lectures <span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="Lectures">
                
                <li class="divider"></li>
                <li><a href="#lec1">Lecture 1</a></li>
                <li><a href="#lec2">Lecture 2</a></li>
                <li><a href="#lec3">Lecture 3</a></li>
                <li><a href="#lec4">Lecture 4</a></li>
                <li><a href="#lec5">Lecture 5</a></li>
                <li><a href="#lec6">Lecture 6</a></li>
                <li><a href="#lec7">Lecture 7</a></li>
                <li><a href="#lec8">Lecture 8</a></li>
                <li><a href="#lec9">Lecture 9</a></li>
                <li><a href="#lec10">Lecture 10</a></li>
    
              </ul>
            </li>

            <li class="dropdown">
              <a class="dropdown-toggle" data-toggle="dropdown" href="#" id="Labs">Labs <span class="caret"></span></a>
              <ul class="dropdown-menu" aria-labelledby="Labs">
                
                <li class="divider"></li>
                <li><a href="#lab1">Lab 1</a></li>
                <li><a href="#lab2">Lab 2</a></li>
                <li><a href="#lab3">Lab 3</a></li>
                <li><a href="#lab4">Lab 4</a></li>
                <li><a href="#lab5">Lab 5</a></li>
                <li><a href="#lab6">Lab 6</a></li>
                <li><a href="#lab7">Lab 7</a></li>
                <li><a href="#lab8">Lab 8</a></li>
                <li><a href="#lab9">Lab 9</a></li>
                <li><a href="#lab10">Lab 10</a></li>
    
              </ul>
            </li>

            <li><a href="#assignment-suggestions">Assignments</a></li>

            
          </ul>
        </div><!--/.nav-collapse -->
      </div>
    </nav>

    <div class="container">
    <div class="row">
    
     
      <div class="span9">
            <h1 id="data-science-and-decision-making">Data Science and Decision Making</h1>
<h3 id="overall">Overall</h3>
<p>This is a new module on Data Science and Decision Making - we will examine most aspects of modern data science and try to create a fully-fledged end-to-end data science study. The module outline can be found <a href="https://www.essex.ac.uk/modules/Default.aspx?coursecode=CE888&amp;year=17">here</a> - but it is still subject to changes. The lecture notes and lab scripts for this course will be made available and further developed during the module.</p>
<p>This is a very hands-on module, where the goal is to give you sufficient breadth and depth to work as an independent data scientist. The course is assessed solely through coursework.</p>
<h3 id="lectures">Lectures</h3>
<p>Lectures take place on <strong>Monday 14:00-16:00 at Room NTC.2.04</strong>.</p>
<p><a id="lec1"></a></p>
<ol style="list-style-type: decimal">
<li><a href="./slides/01-Introduction-slides.pdf">Lecture 1: Introduction</a>, <a href="./slides/01-Introduction-handouts.pdf">Handouts</a></li>
</ol>
<!--

<a id="lec2"></a> 

2. [Lecture 2: Summary and resampling statistics](./slides/02-Stats-Slides.pdf), [Handouts](./slides/02-Stats-handouts.pdf) 

<a id="lec3"></a> 

3. [Lecture 3: Predictive modelling](./slides/03-Modelling-slides.pdf), [Handouts](./slides/03-Modelling-handouts.pdf) 

<a id="lec4"></a> 

4. [Lecture 4: Bandits](./slides/04-Bandits-slides.pdf), [Handouts](./slides/04-Bandits-handouts.pdf) 

<a id="lec5"></a> 

5. [Lecture 5: Recommender systems](./slides/05-Recommender-slides.pdf), [Handouts](./slides/05-Recommender-handouts.pdf) 

<a id="lec6"></a> 

6. [Lecture 6: Data exploration](./slides/06-Exploration-slides.pdf), [Handouts](./slides/06-Exploration-handouts.pdf) 

<a id="lec7"></a> 

7. [Lecture 7: Neural networks](./slides/07-Neural-slides.pdf), [Handouts](./slides/07-Neural-handouts.pdf) 

<a id="lec8"></a> 

8. [Lecture 8: Images, Video, Audio, Text](./slides/08-Text-slides.pdf), [Handouts](./slides/08-Text-handouts.pdf) 

<a id="lec9"></a> 

9. [Lecture 9: Data and Systems](./slides/09-Systems-slides.pdf), [Handouts](./slides/09-Systems-handouts.pdf) 

<a id="lec10"></a> 

10. [Lecture 10: Discussion](./slides/10-Discussion-slides.pdf), [Handouts](./slides/10-Discussion-handouts.pdf) 

-->
<h3 id="labs">Labs</h3>
<p>Labs are every <strong>Tuesday 12:00-15:00, CES Lab 6,7</strong>. Labs are assessed and they should be completed either in class or later on.</p>
<p>Please download the lab Virtual Machine from here: [MLVM Virtual Machine](https://drive.google.com/drive/folders/1SwdnpeJfjzUH7YDgwgrtDb7mve6d4zIe</p>
<p>All labs can be found here: <a href="https://github.com/ssamot/ce888/tree/master/labs/" class="uri">https://github.com/ssamot/ce888/tree/master/labs/</a></p>
<p><a id="lab1"></a></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/ssamot/ce888/tree/master/labs/lab1">Lab 1: VM setup and simple emotion detection</a></li>
</ol>
<!--

<a id="lab2"></a>

2. [Lab 2: Creating plots, overleaf and confidence bounds](https://github.com/ssamot/ce888/tree/master/labs/lab2) 

<a id="lab3"></a>

3. [Lab 3: Jupiter/IPython and Classification](https://github.com/ssamot/ce888/tree/master/labs/lab3) 

<a id="lab4"></a>

4. [Lab 4: Bandits and time series plotting](https://github.com/ssamot/ce888/tree/master/labs/lab4) 

<a id="lab5"></a>

5. [Lab 5: Recommender systems and jokes](https://github.com/ssamot/ce888/tree/master/labs/lab5) 

<a id="lab6"></a>

6. [Lab 6: Clustering and visualisation](https://github.com/ssamot/ce888/tree/master/labs/lab6) 

<a id="lab7"></a>

7. [Lab 7: Neural networks and MNIST](https://github.com/ssamot/ce888/tree/master/labs/lab7) 

<a id="lab8"></a>

8. [Lab 8: IMDB and text data](https://github.com/ssamot/ce888/tree/master/labs/lab8) 
-->
<h3 id="ides">IDEs</h3>
<p>You can use whatever IDE you want for the course, however my proposal would be to use PyCharm - which is installed in the lab machines:</p>
<ul>
<li><a href="https://www.jetbrains.com/pycharm/">PyCharm</a></li>
</ul>
<h3 id="assessment">Assessment</h3>
<p>The objective of the module and the main assignment is to produce a Data Science app (i.e. make use of data to generate results, make inferences, present the results to third parties) and write down the description of the methods and the results in a scientific paper. Some ideas for possible apps are provided <a href="#assignment-suggestions">here</a>.</p>
<!--
* Assigments
    * [Assignment 1](./assignments/ce888-assignment-1.pdf)
    * [Assignment 2](./assignments/ce888-assignment-2.pdf)
-->
<p>See FASER for exact assignment deadlines.</p>
<h3 id="readings">Readings</h3>
<p>Every lecture will come with a set of online reading suggestions - they will be added here.</p>
<p><strong>Lecture 1</strong></p>
<p><a href="https://s3.amazonaws.com/academia.edu.documents/37162300/An_Introduction_to_Statistical_Learning_with_Applications_in_R.pdf?AWSAccessKeyId=AKIAIWOWYYGZ2Y53UL3A&amp;Expires=1515959849&amp;Signature=1vCfZn0dpIe%2FL45pgI2fjn9GrlI%3D&amp;response-content-disposition=inline%3B%20filename%3DPrinter_Opaque_this_An_Introduction_to_S.pdf">James, Gareth, et al. An introduction to statistical learning. Vol. 112. New York: springer, 2013.</a></p>
<p><a href="http://projecteuclid.org/download/pdf_1/euclid.ss/1009213726%20">Breiman, Leo. &quot;Statistical modeling: The two cultures (with comments and a rejoinder by the author).&quot; Statistical Science 16.3 (2001): 199-231.</a></p>
<p><a href="https://www.tkm.kit.edu/downloads/TKM1_2011_more_is_different_PWA.pdf">Anderson, Philip W. &quot;More is different.&quot; Science 177.4047 (1972): 393-396.</a></p>
<!--
**Lecture 2**

[Efron, Bradley, and Robert J. Tibshirani. An introduction to the bootstrap. CRC press, 1994.](http://cds.cern.ch/record/526679/files/0412042312_TOC.pdf)

[Simmons, Joseph P., Leif D. Nelson, and Uri Simonsohn. "False-positive psychology: Undisclosed flexibility in data collection and analysis allows presenting anything as significant." Psychological science 22.11 (2011): 1359-1366.](http://www.haas.berkeley.edu/groups/online_marketing/facultyCV/papers/nelson_false-positive.pdf)

[Schenker, Nathaniel, and Jane F. Gentleman. "On judging the significance of differences by examining the overlap between confidence intervals." The American Statistician 55.3 (2001): 182-186.](htps://www.jstor.org/stable/2685796)

**Lecture 3** 

[Jake VanderPlas, Python Data Science Handbook Essential Tools for Working with Data 2016. O'Reilly Media, 2016](https://github.com/jakevdp/PythonDataScienceHandbook)

[Kohavi, Ron. "A study of cross-validation and bootstrap for accuracy estimation and model selection." IJCAI. Vol. 14. No. 2. 1995.](https://pdfs.semanticscholar.org/0be0/d781305750b37acb35fa187febd8db67bfcc.pdf)

[Geman, Stuart, Elie Bienenstock, and René Doursat. "Neural networks and the bias/variance dilemma." Neural computation 4.1 (1992): 1-58.](https://stuff.mit.edu/afs/athena.mit.edu/course/6/6.435/www/Geman92.pdf)

[scikit-learn's website](http://scikit-learn.org/)

**Lecture 4**

[White, John. Bandit algorithms for website optimization. " O'Reilly Media, Inc.", 2012.](http://shop.oreilly.com/product/0636920027393.do)

[Oza, Nikunj C. "Online bagging and boosting." Systems, man and cybernetics, 2005 IEEE international conference on. Vol. 3. IEEE, 2005.](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20050239012.pdf)

[Osband, Ian, et al. "Deep exploration via bootstrapped DQN." Advances In Neural Information Processing Systems. 2016.](http://papers.nips.cc/paper/6500-deep-exploration-via-bootstrapped-dqn.pdf)

**Lecture 5**

[Simon Funk, Netflix Update: Try This at Home](http://sifter.org/~simon/journal/20061211.html)

[Barkan, Oren, and Noam Koenigstein. "Item2vec: neural item embedding for collaborative filtering." Machine Learning for Signal Processing (MLSP), 2016 IEEE 26th International Workshop on. IEEE, 2016.](https://arxiv.org/pdf/1603.04259.pdf)

[Hu, Yifan, Yehuda Koren, and Chris Volinsky. "Collaborative filtering for implicit feedback datasets." Data Mining, 2008. ICDM'08. Eighth IEEE International Conference on. Ieee, 2008.](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.167.5120&rep=rep1&type=pdf)

**Lecture 6**

[Rousseeuw, Peter J. "Silhouettes: a graphical aid to the interpretation and validation of cluster analysis." Journal of computational and applied mathematics 20 (1987): 53-65.](http://www.sciencedirect.com/science/article/pii/0377042787901257)

[Arthur, David, and Sergei Vassilvitskii. "k-means++: The advantages of careful seeding." Proceedings of the eighteenth annual ACM-SIAM symposium on Discrete algorithms. Society for Industrial and Applied Mathematics, 2007.](http://ilpubs.stanford.edu:8090/778/1/2006-13.pdf)

**Lecture 7**

[Hinton, Geoffrey E., and Ruslan R. Salakhutdinov. "Reducing the dimensionality of data with neural networks." science 313.5786 (2006): 504-507.](https://pdfs.semanticscholar.org/7d76/b71b700846901ac4ac119403aa737a285e36.pdf)

[Goodfellow, Ian, Yoshua Bengio, and Aaron Courville. Deep learning. MIT Press, 2016.](http://www.deeplearningbook.org/)

[Bengio, Yoshua. "Learning deep architectures for AI." Foundations and trends® in Machine Learning 2.1 (2009): 1-127.](http://www.nowpublishers.com/article/DownloadSummary/MAL-006)


**Lecture 8**

[Halevy, Alon, Peter Norvig, and Fernando Pereira. "The unreasonable effectiveness of data." IEEE Intelligent Systems 24.2 (2009): 8-12.](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/35179.pdf)

[Zhou, Zhi-Hua, and Ji Feng. "Deep Forest: Towards An Alternative to Deep Neural Networks." arXiv preprint arXiv:1702.08835 (2017).](https://arxiv.org/pdf/1702.08835.pdf)

**Lecture 9** 

[Dean, Jeffrey, and Sanjay Ghemawat. "MapReduce: simplified data processing on large clusters." Communications of the ACM 51.1 (2008): 107-113.](https://www.usenix.org/legacy/publications/library/proceedings/osdi04/tech/full_papers/dean/dean_html/)
[Karau, Holden, et al. Learning spark: lightning-fast big data analysis. " O'Reilly Media, Inc.", 2015.](http://shop.oreilly.com/product/0636920028512.do)

-->
<h3 id="people">People</h3>
<ul>
<li>Module Supervisor: <em>Spyros Samothrakis</em>, <script type="text/javascript">
<!--
h='&#x65;&#x73;&#x73;&#x65;&#120;&#46;&#x61;&#x63;&#46;&#x75;&#x6b;';a='&#64;';n='&#x73;&#x73;&#x61;&#x6d;&#x6f;&#116;';e=n+a+h;
document.write('<a h'+'ref'+'="ma'+'ilto'+':'+e+'" clas'+'s="em' + 'ail">'+e+'<\/'+'a'+'>');
// -->
</script><noscript>&#x73;&#x73;&#x61;&#x6d;&#x6f;&#116;&#32;&#x61;&#116;&#32;&#x65;&#x73;&#x73;&#x65;&#120;&#32;&#100;&#x6f;&#116;&#32;&#x61;&#x63;&#32;&#100;&#x6f;&#116;&#32;&#x75;&#x6b;</noscript></li>
</ul>
<hr />
<hr />
<h1 id="assignments">Assignments</h1>
<p>Below you will find a list of projects for CE888 - this is still a draft and I will refine the assignments as we get closer each coursework getting formally released.</p>
<h3 id="rl-and-interpretability">RL and Interpretability</h3>
<p>Modern Reinforcement Learning helps agents learn how to act using complex patterns of text, sound and video and it's slowly moving away from research and making inroads to traditional industries (e.g., creating game NPC characters). The high dimensionality of the input space makes it however very hard to interpret why an agent preferred one action over another. In this project we will try to transfer some novel methods from supervised learning to Reinforcement Learning in order to interpret why agents make certain decisions. We will use already existing Atari game playing agents and try to interpret their actions profile in real time, effectively &quot;seeing&quot; through the agent's eyes.</p>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Games</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/pdf/1602.04938v3">Ribeiro, Marco Tulio, Sameer Singh, and Carlos Guestrin. &quot;&quot; Why Should I Trust You?&quot;: Explaining the Predictions of Any Classifier.&quot; KDD (2016).</a></li>
<li><a href="http://zacklipton.com/media/papers/mythos_model_interpretability_lipton2016.pdf">Lipton, Zachary C., et al. &quot;The Mythos of Model Interpretability.&quot; IEEE Spectrum (2016)</a></li>
<li><a href="https://arxiv.org/pdf/1711.00138">Greydanus, Sam, et al. &quot;Visualizing and Understanding Atari Agents.&quot; arXiv preprint arXiv:1711.00138 (2017).</a></li>
<li><a href="https://docs.opencv.org/3.3.1/d7/d8b/tutorial_py_lucas_kanade.html">OpenCV optical flow tutorial</a></li>
</ol>
<p><strong>Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/ppwwyyxx/tensorpack/tree/master/examples/OpenAIGym">Example Open AI gym Atari Controllers - look also in your VM</a></li>
<li><a href="https://github.com/marcotcr/lime">LIME</a></li>
</ol>
<p><strong>Tasks</strong></p>
<ol style="list-style-type: decimal">
<li>Each Atari agent perceives the world through an concatenation of 4 frames and outputs an action. Run agents in at least 6 games, in as diverse states as possible. Collect at least 30,000 data instances per game and load them for further processing.<br />
</li>
<li>Create a sample python programme that takes an instance, passes through the policy network and outputs an action.</li>
<li>Find a useful high level image to pass to LIME (e.g. calculate the optical flow of the sequence of four actions and output a single image with the flow in it).</li>
<li>Use one of the unsupervised learning algorithms from sci-kit learn to break down your data in various segments - are there clear clusters being formed? What is in each cluster?</li>
<li>Create a video of agent actions.</li>
</ol>
<hr />
<h3 id="genetic-programmingauto-ml-for-domain-adaptation">Genetic Programming/Auto-ML for Domain Adaptation</h3>
<p>It is often the case that the source data is not the same as the target data; for example we only have labeled data examples from images of animals we took in artificial captivity conditions (<em>source data</em>), but we would like to classify animals in the wild (<em>target data</em>). We don't however know the labels of the target data, so we have to learn features that fail to discriminate between source and target distributions, but are good enough to actually learn the mapping between those distributions and their labels.</p>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Neural Networks and Learning Systems</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="http://proceedings.mlr.press/v37/ganin15.html">Ganin, Yaroslav, and Victor Lempitsky. &quot;Unsupervised domain adaptation by backpropagation.&quot; International Conference on Machine Learning. 2015.</a></li>
<li><a href="http://zacklipton.com/media/papers/mythos_model_interpretability_lipton2016.pdf">Lipton, Zachary C., et al. &quot;The Mythos of Model Interpretability.&quot; IEEE Spectrum (2016)</a></li>
<li><a href="https://arxiv.org/pdf/1711.00138">Greydanus, Sam, et al. &quot;Visualizing and Understanding Atari Agents.&quot; arXiv preprint arXiv:1711.00138 (2017).</a></li>
</ol>
<p><strong>Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/pumpikano/tf-dann">MNIST-M Dataset, Blobs and related code</a></li>
<li><a href="https://github.com/jindongwang/transferlearning/blob/master/doc/dataset.md#office-31">The office 31 Dataset</a></li>
</ol>
<p><strong>Tasks</strong></p>
<ol style="list-style-type: decimal">
<li>Download and load the above datasets in python, clearly separating the domain and source data.</li>
<li>Use the TPOT classifier to learn good classifiers for all datasets.</li>
<li>Change the scorer of the TPOT classifier to one that takes into account domain adaptation; a good classifier both succeeds in achieving good performance for the source domain, while the features learned fail to discriminate between between source and target domains. You will need to create a scoring function with signature <code>scorer(estimator, X, y)</code>. The estimator passed is an sklearn <code>Pipeline</code> object - you need to get everything but the last part of the pipeline to transform the target data as well.</li>
<li>Evaluate your method in both datasets.</li>
</ol>
<hr />
<h3 id="genetic-programmingauto-ml-for-one-shot-learning">Genetic Programming/Auto-ML for One-Shot Learning</h3>
<p>One of the issues of most ML algorithms is the need for copious amounts of data - neural networks are notorious for that. It might be possible to transform our data in a way that algorithms that algorithms can use a very limited number of examples and still perform well. A possible method for doing this is transforming classification/regression tasks to metric learning tasks, i.e. how far away is a new data instance from ones observed already.</p>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Neural Networks and Learning Systems</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://sorenbouma.github.io/blog/oneshot/">One Shot Learning and Siamese Networks in Keras</a></li>
<li><a href="https://staff.fnwi.uva.nl/t.e.j.mensink/zsl2016/zslpubs/lake15science.pdf">Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. &quot;Human-level concept learning through probabilistic program induction.&quot; Science 350.6266 (2015): 1332-1338.</a></li>
</ol>
<p><strong>Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/brendenlake/omniglot">Omniglot dataset</a></li>
</ol>
<p><strong>Tasks:</strong></p>
<ol style="list-style-type: decimal">
<li>Download and load the above datasets in python, clearly separating the training and the test data. Generate image combinations (same /different) according the blog post above (reference 2)</li>
<li>Use the TPOT classifier to learn the metric - as a common classification with probabilities task.</li>
<li>Change the scorer of the TPOT classifier; a good scorer both succeeds in achieving good performance for the original task, while the features learned fail to discriminate between between source and target domain. You will need to create a scoring function with signature <code>scorer(estimator, X, y)</code>. The estimator passed is an sklearn Pipeline object - manipulate it to get any. Re-run TPOT with your new scorer and record the results.</li>
<li>Try to use methods for upsampling/downsampling to capture the the fact that your dataset is now imbalanced - incorporate them within TPOT's pipeline if you can.</li>
</ol>
<hr />
<h3 id="continual-learning-using-auto-encoders">Continual Learning using auto-encoders</h3>
<p>One of the most important unsolved issues in Machine Learning is learning concepts incrementally. For this project we will try</p>
<p><strong>Target Journal/Conference:</strong> IEEE Transactions on Neural Networks and Learning Systems</p>
<p><strong>References:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://blog.keras.io/building-autoencoders-in-keras.html">Keras Autoencoder</a></li>
<li><a href="http://www.pnas.org/content/114/13/3521.full">Kirkpatrick, James, et al. &quot;Overcoming catastrophic forgetting in neural networks.&quot; Proceedings of the National Academy of Sciences (2017): 201611835.</a></li>
<li><a href="https://arxiv.org/pdf/1312.6211.pdf">Goodfellow, Ian J., et al. &quot;An empirical investigation of catastrophic forgetting in gradient-based neural networks.&quot; arXiv preprint arXiv:1312.6211 (2013).</a></li>
</ol>
<p><strong>Data:</strong></p>
<ol style="list-style-type: decimal">
<li><a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST dataset</a></li>
<li><a href="https://github.com/keras-team/keras/blob/master/examples/cifar10_cnn.py">CIFAR10 dataset</a></li>
</ol>
<p><strong>Tasks</strong></p>
<ol style="list-style-type: decimal">
<li>Create three or more tasks of MNIST digits by permuting the pixels (i.e shuffling the images) in a fixed way for each task and save the new datasets in a file. Do the same with CIFAR10 data.</li>
<li>Instantiate <span class="math inline"><em>n</em></span> of keras/neural network autoencoders and associate an instance of a classifier with each one.</li>
<li>Send data in batches and pick the auto-encoder with the lowest error - train the autoencoder and the associated classifier with that batch.</li>
<li>Evaluate the setup in all tasks.</li>
<li>Redo the above experiment with an increased amount of autoencoders (<span class="math inline"><em>n</em> + 1</span>).</li>
<li>Create new autoencoders on the fly if the error is too high.</li>
</ol>
<hr />
<hr />
<hr />
            </div>
    </div>
  </div>

    <!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.12.4/jquery.min.js"></script>
    <!-- Include all compiled plugins (below), or include individual files as needed -->
    <script src="bootstrap/js/bootstrap.min.js"></script>
  </body>
</html>